{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Ray Tutorial and Deep Q Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the tutorial we showcase what ray can do to speed up code and functions.  We will show how a simple decorator function enables a standard written python function to be run in a parallelized manner and distributed across nodes.\n",
    "\n",
    "The second part of this tutorial focuses on the cart-pole problem. A cart has a pole fixed with a movable lever in the middle of the cart. The cart slides along a frictionless surface. The goal is to keep the pole upright at all times. The test is how far back and forth the cart can move in order to prevent the pole from falling. The tutorial has been modified heavily so that it (i) runs in a jupyter notebook, (ii) demonstrates full capabilities of ray, and ray tune and (iii) breaks down the components of a RL project along with enhanced explainations of the code. We may modify this tutorial further to solve a different problem.\n",
    "\n",
    "In the third part of the tutorial, we demonstrate how to create a custom reinforcement learning environment with the problem space of a robot walking down a corridor.\n",
    "\n",
    "#### References:\n",
    "\n",
    "Barto, A. G., Sutton, R. S. and Anderson, C. (1983), ‘Neuron-like adaptive elements that can solve difficult learning control problems’, IEEE Transactions on Systems, 5, Man, and Cybernetics 13, 834–846\n",
    "\n",
    "Tune: A Research Platform for Distributed Model Selection and Training, Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion, arXiv preprint arXiv:1807.05118}, 2018\n",
    "\n",
    "Ray RLLib Documentation: [Ray RLLib Documentation](https://docs.ray.io/en/latest/rllib-training.html#getting-started)\n",
    "\n",
    "Ray Tune Documentation: [Ray Tune Documentation](https://docs.ray.io/en/latest/tune/index.html)\n",
    "\n",
    "Mastering Reinforcement Learning with Python, Enes Bilgin, Packt Publishing, 2020 [Buy MRL with Python](https://www.amazon.com/Mastering-Reinforcement-Learning-Python-next-generation/dp/1838644148/?tag=meastus-200)\n",
    "\n",
    "Example of Calculating Pi using Ray [How to scale Python multiprocessing to a cluster with one line of code by Evan Oaks](https://medium.com/distributed-computing-with-ray/how-to-scale-python-multiprocessing-to-a-cluster-with-one-line-of-code-d19f242f60ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Ray Version, Instantiating Ray Instances and Looking at Node Parameters\n",
    "\n",
    "Its typically helpful to check the parameters for nodes to ensure that they are in good shape.  One can also navigate to the tab which says 'Ray Web UI) to look through the node pool and ray actors as well as memory.  These are advanced topics and are meant for trouble-shooting only. \n",
    "\n",
    "\n",
    "In this notebook we'll start with showing you how easy it is to use Ray to convert regular functions into ones that are parallelized and distributed across nodes.  Before we do anything though, let's check our version of Ray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray, version 1.9.0\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   #_temp_dir='/domino/datasets/local/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "   ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the health of the nodes, look at their CPU and GPU per node.  Here you can see each node, including the head node have seven GPUs (this may differ in your example depending on your environment).  It's a good idea to check this and plan for memory usuage with Ray.  If there isn't enough memory overhead for the code as written, a data channel error will shutdown.  There are advanced techniques to prevent this.  This happens regardless of the verison of Ray used, so make sure to check each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '1fdc47da06fd5fd9ebb7a0d6e25ffef999766db14e84093c6e7da1da',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.45.20',\n",
       "  'NodeManagerHostname': 'ray-61ddddeb0bbd833830273b3e-ray-worker-2',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/raylet',\n",
       "  'MetricsExportPort': 58583,\n",
       "  'alive': True,\n",
       "  'Resources': {'object_store_memory': 8677033574.0,\n",
       "   'CPU': 6.0,\n",
       "   'memory': 20246411674.0,\n",
       "   'node:10.0.45.20': 1.0}},\n",
       " {'NodeID': '28a11237f6f4dfa5845ea45db75eccf3ffb19be11e97e3b9498ab7bc',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.42.199',\n",
       "  'NodeManagerHostname': 'ray-61ddddeb0bbd833830273b3e-ray-worker-1',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/raylet',\n",
       "  'MetricsExportPort': 62305,\n",
       "  'alive': True,\n",
       "  'Resources': {'node:10.0.42.199': 1.0,\n",
       "   'CPU': 6.0,\n",
       "   'object_store_memory': 8676968448.0,\n",
       "   'memory': 20246259712.0}},\n",
       " {'NodeID': '4cf45ef28d4fbd90497188b5678376bb955facc3b04352d5c2dc3ce9',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.35.140',\n",
       "  'NodeManagerHostname': 'ray-61ddddeb0bbd833830273b3e-ray-worker-3',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/raylet',\n",
       "  'MetricsExportPort': 57238,\n",
       "  'alive': True,\n",
       "  'Resources': {'memory': 20250434356.0,\n",
       "   'CPU': 6.0,\n",
       "   'object_store_memory': 8678757580.0,\n",
       "   'node:10.0.35.140': 1.0}},\n",
       " {'NodeID': '11300b795f64464e683105fa3600e8163cc953e3c9d81083dab9bc15',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.57.104',\n",
       "  'NodeManagerHostname': 'ray-61ddddeb0bbd833830273b3e-ray-head-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/raylet',\n",
       "  'MetricsExportPort': 53992,\n",
       "  'alive': True,\n",
       "  'Resources': {'CPU': 6.0,\n",
       "   'memory': 17357539739.0,\n",
       "   'node:10.0.57.104': 1.0,\n",
       "   'object_store_memory': 8678769868.0}},\n",
       " {'NodeID': '34353fc15202ff4fab92b09b69db2932157e84a77ac4a183011d5f64',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.60.133',\n",
       "  'NodeManagerHostname': 'ray-61ddddeb0bbd833830273b3e-ray-worker-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-01-11_19-53-18_620358_1/sockets/raylet',\n",
       "  'MetricsExportPort': 58264,\n",
       "  'alive': True,\n",
       "  'Resources': {'object_store_memory': 8678784614.0,\n",
       "   'node:10.0.60.133': 1.0,\n",
       "   'CPU': 6.0,\n",
       "   'memory': 20250497434.0}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ray and what can it do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray is a flexible distributed computing system available on Domino product on demand.  With Ray one can run code both in parallel or in distributed mode.  Parallel mode refers to running a function on several threads simultaneously in parallel.  This method can also be accomplished on multiple nodes at once (distributed computing).  One will notice that the wall clock time (which we compute below) differs from the compute time.  With multiple nodes or threading (running in a distributed fashion), the compute time is split among nodes.  Thus when we provide a 10 second 'sleep' we can see that the 10 seconds is distributed and so the wall clock time (the time we actually experience) is shorter than compute time.  This is part of the magic of parallel and distributed computing.  Let's take a closer look below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "Time taken:  10.00560736656189\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import ray\n",
    "\n",
    "\n",
    "y = 1\n",
    "object_ref = y\n",
    "\n",
    "def add(x, a=1):\n",
    "    if x == 'add':\n",
    "        answer = a + 1\n",
    "    else:\n",
    "        answer = a\n",
    "    time.sleep(5)\n",
    "    print(answer)\n",
    "    \n",
    "number_add =add('add')\n",
    "number_none =add('hello')\n",
    "        \n",
    "object_ids = []\n",
    "st = time.time()\n",
    "for x in range(2):\n",
    "    y_id = add('add')\n",
    "    object_ids.append(y_id) # the object ids will print out\n",
    "    \n",
    "## getting the results to pass to another function\n",
    "objects = object_ids\n",
    "end = time.time()\n",
    "print(\"Time taken: \", str(end-st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating remote objects\n",
    "\n",
    "Put an object in Ray's object store, get it out and run the function\n",
    "say want to add 10 million and after every million 5 seconds, total processing would be 50 seconds\n",
    "\n",
    "Do this in ray, and have 3 ray workers, adding 1 million values each, \n",
    "after calculating 1 million each sleeps 5 seconds, then total processing takes less than six seconds\n",
    "iterations in learning \n",
    "ml is already iterative, running partitions on each worker and at the distributed sequentially now paralellized\n",
    "call without ray and then with ray\n",
    "small amount of data, run and then kick off with same code but a larger data set, locally and in cloud testuse 10 workers, each sleeps 2 seconds, and see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(add pid=383)\u001b[0m 2\n",
      "\u001b[2m\u001b[36m(add pid=383)\u001b[0m 1\n",
      "5.008830547332764\n",
      "\u001b[2m\u001b[36m(add pid=383)\u001b[0m 2\n",
      "\u001b[2m\u001b[36m(add pid=130, ip=100.96.17.136)\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "y = 1\n",
    "object_ref = ray.put(y)\n",
    "\n",
    "@ray.remote\n",
    "def add(x, a=1):\n",
    "    if x == 'add':\n",
    "        answer = a + 1\n",
    "    else:\n",
    "        answer = a\n",
    "    time.sleep(5)\n",
    "    print(answer)\n",
    "    \n",
    "number_add = ray.get(add.remote('add'))\n",
    "number_none = ray.get(add.remote('hello'))\n",
    "        \n",
    "object_ids = []\n",
    "st = time.time()\n",
    "for x in range(2):\n",
    "    y_id = add.remote('add')\n",
    "    object_ids.append(y_id) # the object ids will print out\n",
    "    \n",
    "## getting the results to pass to another function\n",
    "objects = ray.get(object_ids)\n",
    "end = time.time()\n",
    "print(str(end-st))\n",
    "\n",
    "#notice that the process ids (pid) have the same number (223) except for the head node which has the number 221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "def sample(num_samples):\n",
    "    num_inside = 0\n",
    "    for _ in range(num_samples):\n",
    "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "        if math.hypot(x, y) <= 1:\n",
    "            num_inside += 1\n",
    "    return num_inside\n",
    "\n",
    "def approximate_pi(num_samples):\n",
    "    start = time.time()\n",
    "    num_inside = sample(num_samples)\n",
    "    \n",
    "    print(\"pi ~= {}\".format((4*num_inside)/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi ~= 3.14167832\n",
      "CPU times: user 1min 4s, sys: 33.3 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "approximate_pi(10**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "def sample(num_samples):\n",
    "    num_inside = 0\n",
    "    for _ in range(num_samples):\n",
    "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "        if math.hypot(x, y) <= 1:\n",
    "            num_inside += 1\n",
    "    return num_inside\n",
    "\n",
    "def approximate_pi_parallel(num_samples):\n",
    "    from multiprocessing.pool import Pool\n",
    "    pool = Pool()\n",
    "    \n",
    "    start = time.time()\n",
    "    num_inside = 0\n",
    "    sample_batch_size = 100000\n",
    "    for result in pool.map(sample, [sample_batch_size for _ in range(num_samples//sample_batch_size)]):\n",
    "        num_inside += result\n",
    "        \n",
    "    print(\"pi ~= {}\".format((4*num_inside)/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi ~= 3.14162348\n",
      "CPU times: user 9.36 s, sys: 986 ms, total: 10.3 s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "approximate_pi_parallel(10**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "def sample(num_samples):\n",
    "    num_inside = 0\n",
    "    for _ in range(num_samples):\n",
    "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
    "        if math.hypot(x, y) <= 1:\n",
    "            num_inside += 1\n",
    "    return num_inside\n",
    "\n",
    "def approximate_pi_distributed(num_samples):\n",
    "    from ray.util.multiprocessing.pool import Pool # NOTE: Only the import statement is changed.\n",
    "    pool = Pool()\n",
    "        \n",
    "    start = time.time()\n",
    "    num_inside = 0\n",
    "    sample_batch_size = 100000\n",
    "    for result in pool.map(sample, [sample_batch_size for _ in range(num_samples//sample_batch_size)]):\n",
    "        num_inside += result\n",
    "        \n",
    "    print(\"pi ~= {}\".format((4*num_inside)/num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi ~= 3.14141856\n",
      "CPU times: user 17.5 s, sys: 1.72 s, total: 19.2 s\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "approximate_pi_distributed(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the above examples the compute time differs and the wall clock time for the compute differs. However keep in mind Ray is only using three workers to calculate pi in this simple example becasue we started the cluster with three workers.  If the cluster is started with more workers, it will speed up the calculations every further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cart Pole Problem\n",
    "\n",
    "Training with hyperparameter tuning was traditionally very human-time intensive. With the Ray 'tune' tool, hyper-parameter tuning is automated.  Ray is not the only software that can do this neat trick of parallel and distributed compute.  It can be done with any distributed system.  Ray just happens to particularlly excell at deeep learning and reinforcement learning.  \n",
    "\n",
    "RLlib is an open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications. RLlib natively supports TensorFlow, TensorFlow Eager, and PyTorch, but most of its internals are framework agnostic. See the docs [here](https://docs.ray.io/en/latest/rllib.html) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Cart-Pole Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the best learning rate using Ray's Tune library\n",
    "\n",
    "The example below shows how to use Ray's Tune library with the cart-pole problem.  The best learning rate can be determined by the reward amount.  Its a best practise to shutdown and re start your distributed computing system each time.  This allows the workers to clear their memory.  In addition the example below is one where we run the cart-pole problem in a distributed manner.  We'll show a second example where we run the experiment in a parallel manner.  In this distributed example you'll see that it takes less than 20 seconds to run the entire training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   _temp_dir='/domino/datasets/local/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "   ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Current time: 2022-01-11 19:57:58 (running for 00:00:03.24)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Memory usage on this node: 3.7/31.4 GiB\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Resources requested: 0/30 CPUs, 0/0 GPUs, 0.0/91.6 GiB heap, 0.0/40.41 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Number of trials: 3/3 (3 PENDING)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | Trial name                  | status   | loc   |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m |-----------------------------+----------+-------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00000 | PENDING  |       | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00001 | PENDING  |       | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00002 | PENDING  |       | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.35.140)\u001b[0m 2022-01-11 19:58:03,356\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.35.140)\u001b[0m 2022-01-11 19:58:03,356\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.35.140)\u001b[0m 2022-01-11 19:58:03,356\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.45.20)\u001b[0m 2022-01-11 19:58:03,367\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.45.20)\u001b[0m 2022-01-11 19:58:03,367\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.45.20)\u001b[0m 2022-01-11 19:58:03,367\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.42.199)\u001b[0m 2022-01-11 19:58:03,379\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.42.199)\u001b[0m 2022-01-11 19:58:03,380\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.42.199)\u001b[0m 2022-01-11 19:58:03,380\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=239, ip=10.0.35.140)\u001b[0m 2022-01-11 19:58:07,192\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=239, ip=10.0.42.199)\u001b[0m 2022-01-11 19:58:07,283\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=239, ip=10.0.45.20)\u001b[0m 2022-01-11 19:58:07,286\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.35.140)\u001b[0m 2022-01-11 19:58:08,908\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.42.199)\u001b[0m 2022-01-11 19:58:08,971\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=240, ip=10.0.45.20)\u001b[0m 2022-01-11 19:58:08,997\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Current time: 2022-01-11 19:58:10 (running for 00:00:14.82)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Memory usage on this node: 3.7/31.4 GiB\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Resources requested: 6.0/30 CPUs, 0/0 GPUs, 0.0/91.6 GiB heap, 0.0/40.41 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | Trial name                  | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m |-----------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00000 | RUNNING  | 10.0.35.140:240 | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00001 | RUNNING  | 10.0.45.20:240  | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00002 | RUNNING  | 10.0.42.199:240 | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Current time: 2022-01-11 19:58:11 (running for 00:00:15.83)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Memory usage on this node: 3.7/31.4 GiB\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Resources requested: 6.0/30 CPUs, 0/0 GPUs, 0.0/91.6 GiB heap, 0.0/40.41 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | Trial name                  | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m |-----------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00000 | RUNNING  | 10.0.35.140:240 | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00001 | RUNNING  | 10.0.45.20:240  | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00002 | RUNNING  | 10.0.42.199:240 | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result for DQN_CartPole-v0_c4071_00000:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   date: 2022-01-11_19-58-12\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_len_mean: 20.645833333333332\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_max: 56.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_mean: 20.645833333333332\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_min: 10.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_this_iter: 48\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_total: 48\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   experiment_id: f7857542abc540cf94537eb897f24cd7\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   hostname: ray-61ddddeb0bbd833830273b3e-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           cur_lr: 0.009999999776482582\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           max_q: 0.42983779311180115\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_q: -0.10521098226308823\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_td_error: -1.066210389137268\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           min_q: -0.6506630182266235\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8687195777893066\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7844275832176208\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.040654182434082\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.320429801940918\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2324260473251343\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.7653225660324097\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -2.0134963989257812\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.4799745082855225\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9577421545982361\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.07112887501716614\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.4202423095703125\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2352392673492432\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2030775547027588\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.189927339553833\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2472221851348877\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.34579336643219\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.41197821497917175\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -2.115389823913574\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8041847348213196\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2283079624176025\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8144006133079529\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.1870205402374268\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7844275832176208\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9781147241592407\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.173639178276062\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9804778099060059\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.881999135017395\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.12741008400917053\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.15854111313819885\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.6933692693710327\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.3839529752731323\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.3619524240493774\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   node_ip: 10.0.35.140\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     cpu_util_percent: 15.250000000000002\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     ram_util_percent: 11.4\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   pid: 240\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_action_processing_ms: 0.07651283309890793\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_wait_ms: 0.07455665748436134\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_inference_ms: 1.2736337168233378\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_raw_obs_processing_ms: 0.16759897207284905\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_since_restore: 2.494431734085083\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_this_iter_s: 2.494431734085083\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_total_s: 2.494431734085083\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_throughput: 149.207\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_time_ms: 214.467\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_throughput: 111199.443\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_time_ms: 0.288\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     update_time_ms: 4.337\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timestamp: 1641931092\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   trial_id: c4071_00000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result for DQN_CartPole-v0_c4071_00002:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   date: 2022-01-11_19-58-12\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_len_mean: 23.878048780487806\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_max: 60.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_mean: 23.878048780487806\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_min: 9.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_this_iter: 41\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_total: 41\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   experiment_id: 51edf3de14e1474e96b864e50bace764\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   hostname: ray-61ddddeb0bbd833830273b3e-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           cur_lr: 9.999999747378752e-05\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           max_q: 0.586143434047699\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_q: 0.04528075456619263\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_td_error: -0.8307848572731018\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           min_q: -0.5925273299217224\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9725480675697327\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.5328962802886963\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.0383223295211792\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9971612691879272\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7809628844261169\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.3151063919067383\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.6729428172111511\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.4083364009857178\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.5069684386253357\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9565554857254028\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7577305436134338\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8989891409873962\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9866034388542175\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.587016761302948\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.17906159162521362\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.1975454092025757\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.5490651726722717\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.9444308280944824\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.6486871242523193\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.407082438468933\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.2912624180316925\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8748781085014343\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.012830376625061\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8499972820281982\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.1674979329109192\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.4629307687282562\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.6326797008514404\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8989891409873962\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.2937794923782349\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.3966834545135498\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.010892391204834\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -1.6896767616271973\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   node_ip: 10.0.42.199\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     cpu_util_percent: 14.85\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     ram_util_percent: 11.4\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   pid: 240\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_action_processing_ms: 0.07846305420348693\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_wait_ms: 0.07775637296053556\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_inference_ms: 1.2937923530479531\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_raw_obs_processing_ms: 0.1681903740028282\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_since_restore: 2.5267319679260254\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_this_iter_s: 2.5267319679260254\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_total_s: 2.5267319679260254\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_throughput: 146.07\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_time_ms: 219.074\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_throughput: 110104.781\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_time_ms: 0.291\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     update_time_ms: 4.351\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timestamp: 1641931092\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   trial_id: c4071_00002\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result for DQN_CartPole-v0_c4071_00001:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   date: 2022-01-11_19-58-12\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_len_mean: 23.69047619047619\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_max: 67.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_mean: 23.69047619047619\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episode_reward_min: 8.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_this_iter: 42\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   episodes_total: 42\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   experiment_id: bb9193602dd0453fac025b8e4bcf5de6\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   hostname: ray-61ddddeb0bbd833830273b3e-ray-worker-2\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           cur_lr: 0.0010000000474974513\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           max_q: 1.0182312726974487\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_q: 0.1668786108493805\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           mean_td_error: -0.4615628123283386\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           min_q: -0.447528213262558\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.1360006332397461\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7655899524688721\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8096704483032227\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.02659916877746582\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.4849441945552826\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.01823127269744873\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.607723593711853\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.3809570074081421\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7599583864212036\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.3957235813140869\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.6847288608551025\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.31447017192840576\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.2585628628730774\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7480981945991516\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.600443422794342\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.2846564054489136\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.519711971282959\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7853343486785889\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7503695487976074\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8608301281929016\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.7415059208869934\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8890601992607117\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.61260986328125\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.5753602981567383\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8638242483139038\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.826174259185791\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.12586739659309387\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.2815729081630707\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.871785044670105\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.4713624119758606\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - 0.47851306200027466\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m         - -0.8676707744598389\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   node_ip: 10.0.45.20\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     cpu_util_percent: 15.725000000000001\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     ram_util_percent: 11.55\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   pid: 240\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_action_processing_ms: 0.0792664366883117\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_env_wait_ms: 0.07924666771521936\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_inference_ms: 1.3214565299964929\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     mean_raw_obs_processing_ms: 0.17108259858427705\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_since_restore: 2.565775156021118\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_this_iter_s: 2.565775156021118\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   time_total_s: 2.565775156021118\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_throughput: 150.212\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     learn_time_ms: 213.033\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_throughput: 100087.791\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     load_time_ms: 0.32\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m     update_time_ms: 4.507\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timestamp: 1641931092\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   trial_id: c4071_00001\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Current time: 2022-01-11 19:58:12 (running for 00:00:17.46)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Memory usage on this node: 3.7/31.4 GiB\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Resources requested: 0/30 CPUs, 0/0 GPUs, 0.0/91.6 GiB heap, 0.0/40.41 GiB objects\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m Number of trials: 3/3 (3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | Trial name                  | status     | loc             |     lr |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m |-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00000 | TERMINATED | 10.0.35.140:240 | 0.01   |      1 |          2.49443 | 1000 |  20.6458 |                   56 |                   10 |            20.6458 |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00001 | TERMINATED | 10.0.45.20:240  | 0.001  |      1 |          2.56578 | 1000 |  23.6905 |                   67 |                    8 |            23.6905 |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m | DQN_CartPole-v0_c4071_00002 | TERMINATED | 10.0.42.199:240 | 0.0001 |      1 |          2.52673 | 1000 |  23.878  |                   60 |                    9 |            23.878  |\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m +-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=749)\u001b[0m 2022-01-11 19:58:12,994\tINFO tune.py:626 -- Total run time: 18.32 seconds (17.42 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"DQN\",\n",
    "    stop={\"episode_reward_mean\": 1},\n",
    "    config={\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 1,\n",
    "        \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    },\n",
    ")\n",
    "\n",
    "#print(\"Best configuration: \", analysis.best_config)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through multiple iterations to find the best policy\n",
    "\n",
    "In this example we see that a single node can perform the training.  It takes less than a minute to finish the training loop.  After the data is collected from the training iterations (10), we can look at the results to determine the maximum, mean and minimum reward.  We graph that.  For this notebook you can choose which log files you would like to see using the input.  See what your results look like!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 19:58:22,956\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-01-11 19:58:22,960\tWARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.77gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.47.167',\n",
       " 'raylet_ip_address': '10.0.47.167',\n",
       " 'redis_address': '10.0.47.167:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-01-11_19-58-20_349079_632/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-01-11_19-58-20_349079_632/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2022-01-11_19-58-20_349079_632',\n",
       " 'metrics_export_port': 61240,\n",
       " 'node_id': 'a0473c6cd3151a9a5cfc78d9769053cd8c3f06cfd24cfd382f835f6a'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 19:58:24,915\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "2022-01-11 19:58:24,916\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-01-11 19:58:24,917\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=816)\u001b[0m 2022-01-11 19:58:29,337\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "2022-01-11 19:58:30,965\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 1000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-58-34\n",
      "done: false\n",
      "episode_len_mean: 21.88888888888889\n",
      "episode_media: {}\n",
      "episode_reward_max: 53.0\n",
      "episode_reward_mean: 21.88888888888889\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 45\n",
      "episodes_total: 45\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 1000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.9746882915496826\n",
      "        mean_q: 0.021092485636472702\n",
      "        mean_td_error: -0.6288041472434998\n",
      "        min_q: -0.608495831489563\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -1.0691776275634766\n",
      "      - -0.22702759504318237\n",
      "      - -0.6174243688583374\n",
      "      - -1.0176359415054321\n",
      "      - -0.014757335186004639\n",
      "      - -1.0878559350967407\n",
      "      - -0.17425566911697388\n",
      "      - -0.9877854585647583\n",
      "      - -0.9409912824630737\n",
      "      - -0.8639929890632629\n",
      "      - -0.8982413411140442\n",
      "      - 0.22982561588287354\n",
      "      - -0.6192736029624939\n",
      "      - -0.5149320363998413\n",
      "      - -0.7402275204658508\n",
      "      - -0.9744658470153809\n",
      "      - -1.1575816869735718\n",
      "      - -0.8670454025268555\n",
      "      - -0.7087262272834778\n",
      "      - -0.8058916330337524\n",
      "      - -0.8547499775886536\n",
      "      - 0.09230631589889526\n",
      "      - -0.6499912738800049\n",
      "      - -0.8188586831092834\n",
      "      - -0.03899890184402466\n",
      "      - -0.8191032409667969\n",
      "      - -0.047020018100738525\n",
      "      - -0.17647784948349\n",
      "      - -0.6263668537139893\n",
      "      - -0.5756984949111938\n",
      "      - -0.6499913334846497\n",
      "      - -0.8993181586265564\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 32\n",
      "  num_steps_sampled: 1000\n",
      "  num_steps_trained: 32\n",
      "  num_target_updates: 1\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 16.025\n",
      "  ram_util_percent: 14.7\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07888772985437414\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07856428087293565\n",
      "  mean_inference_ms: 1.2076517918726781\n",
      "  mean_raw_obs_processing_ms: 0.17377403708961936\n",
      "time_since_restore: 2.4939827919006348\n",
      "time_this_iter_s: 2.4939827919006348\n",
      "time_total_s: 2.4939827919006348\n",
      "timers:\n",
      "  learn_throughput: 150.144\n",
      "  learn_time_ms: 213.129\n",
      "  load_throughput: 108240.103\n",
      "  load_time_ms: 0.296\n",
      "  update_time_ms: 6.11\n",
      "timestamp: 1641931114\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 1000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /home/ubuntu/ray_results/DQN_CartPole-v0_2022-01-11_19-58-24rg2tyl6a/checkpoint_000001/checkpoint-1\n",
      "agent_timesteps_total: 2000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-58-40\n",
      "done: false\n",
      "episode_len_mean: 20.091836734693878\n",
      "episode_media: {}\n",
      "episode_reward_max: 53.0\n",
      "episode_reward_mean: 20.091836734693878\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 53\n",
      "episodes_total: 98\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 1504\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 3.663027286529541\n",
      "        mean_q: 2.5119946002960205\n",
      "        mean_td_error: 0.11730653047561646\n",
      "        min_q: 1.9546793699264526\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.06405282020568848\n",
      "      - 0.07242774963378906\n",
      "      - -0.09928369522094727\n",
      "      - 0.354320764541626\n",
      "      - 0.9546793699264526\n",
      "      - -0.0504305362701416\n",
      "      - 1.222571849822998\n",
      "      - -0.0368809700012207\n",
      "      - 0.16969728469848633\n",
      "      - -0.10902595520019531\n",
      "      - 0.054564714431762695\n",
      "      - -0.016575336456298828\n",
      "      - 0.028285741806030273\n",
      "      - -0.06340789794921875\n",
      "      - 0.9911773204803467\n",
      "      - 0.03569936752319336\n",
      "      - -0.21771812438964844\n",
      "      - 0.09718060493469238\n",
      "      - -0.07003259658813477\n",
      "      - -0.12677836418151855\n",
      "      - -0.918391227722168\n",
      "      - 1.062638521194458\n",
      "      - 0.02371501922607422\n",
      "      - 1.0633759498596191\n",
      "      - -0.22149395942687988\n",
      "      - 0.02574896812438965\n",
      "      - 0.23399710655212402\n",
      "      - -0.17935562133789062\n",
      "      - -1.1488494873046875\n",
      "      - 0.2760782241821289\n",
      "      - 0.2610023021697998\n",
      "      - 0.02081918716430664\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 8032\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 8032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 2\n",
      "iterations_since_restore: 2\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.55\n",
      "  ram_util_percent: 14.7625\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07841487520657762\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07886234080381074\n",
      "  mean_inference_ms: 1.1941705180272277\n",
      "  mean_raw_obs_processing_ms: 0.1752820732535825\n",
      "time_since_restore: 8.278634071350098\n",
      "time_this_iter_s: 5.784651279449463\n",
      "time_total_s: 8.278634071350098\n",
      "timers:\n",
      "  learn_throughput: 9042.311\n",
      "  learn_time_ms: 3.539\n",
      "  load_throughput: 129254.361\n",
      "  load_time_ms: 0.248\n",
      "  update_time_ms: 2.553\n",
      "timestamp: 1641931120\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 2000\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 3000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-58-46\n",
      "done: false\n",
      "episode_len_mean: 21.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 78.0\n",
      "episode_reward_mean: 21.21\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 138\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 2512\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 5.235931396484375\n",
      "        mean_q: 3.8122873306274414\n",
      "        mean_td_error: 0.2742937207221985\n",
      "        min_q: 1.5334689617156982\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.05341958999633789\n",
      "      - -1.2080200910568237\n",
      "      - 2.5260353088378906\n",
      "      - -0.18850326538085938\n",
      "      - -0.01813483238220215\n",
      "      - -0.04952239990234375\n",
      "      - 0.1750493049621582\n",
      "      - 0.7042008638381958\n",
      "      - 2.075817108154297\n",
      "      - 1.6441864967346191\n",
      "      - 0.024903297424316406\n",
      "      - 1.9563822746276855\n",
      "      - 0.5334689617156982\n",
      "      - -0.04748678207397461\n",
      "      - -0.10013866424560547\n",
      "      - 0.7013908624649048\n",
      "      - -0.28694629669189453\n",
      "      - -0.08026742935180664\n",
      "      - 0.9470844268798828\n",
      "      - 0.38890790939331055\n",
      "      - -0.12898492813110352\n",
      "      - -0.9919095039367676\n",
      "      - -0.06015777587890625\n",
      "      - -0.2175273895263672\n",
      "      - 1.3404922485351562\n",
      "      - -0.21155881881713867\n",
      "      - 0.08202028274536133\n",
      "      - 0.22251558303833008\n",
      "      - -0.5901246070861816\n",
      "      - -0.19370341300964355\n",
      "      - 0.13236284255981445\n",
      "      - -0.25101327896118164\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 16032\n",
      "  num_steps_sampled: 3000\n",
      "  num_steps_trained: 16032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 4\n",
      "iterations_since_restore: 3\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.299999999999997\n",
      "  ram_util_percent: 14.8\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07796201025642445\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07916158223789026\n",
      "  mean_inference_ms: 1.1805850612640214\n",
      "  mean_raw_obs_processing_ms: 0.17555532530992482\n",
      "time_since_restore: 13.965776920318604\n",
      "time_this_iter_s: 5.687142848968506\n",
      "time_total_s: 13.965776920318604\n",
      "timers:\n",
      "  learn_throughput: 8430.126\n",
      "  learn_time_ms: 3.796\n",
      "  load_throughput: 126584.672\n",
      "  load_time_ms: 0.253\n",
      "  update_time_ms: 2.67\n",
      "timestamp: 1641931126\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 3000\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 4000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-58-51\n",
      "done: false\n",
      "episode_len_mean: 26.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 80.0\n",
      "episode_reward_mean: 26.07\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 26\n",
      "episodes_total: 164\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 3520\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 7.757924556732178\n",
      "        mean_q: 5.897418022155762\n",
      "        mean_td_error: -0.10573864728212357\n",
      "        min_q: 1.2117247581481934\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -1.5071988105773926\n",
      "      - 0.16314983367919922\n",
      "      - 0.2651515007019043\n",
      "      - -0.32310914993286133\n",
      "      - 0.264406681060791\n",
      "      - 0.4106912612915039\n",
      "      - 0.23987388610839844\n",
      "      - 0.21172475814819336\n",
      "      - -0.1673717498779297\n",
      "      - 0.17961406707763672\n",
      "      - 0.12034845352172852\n",
      "      - -1.0412354469299316\n",
      "      - -0.08154535293579102\n",
      "      - 0.04455375671386719\n",
      "      - -0.17339754104614258\n",
      "      - 0.05551338195800781\n",
      "      - -0.07104825973510742\n",
      "      - -1.0612778663635254\n",
      "      - -0.46730995178222656\n",
      "      - 0.13152647018432617\n",
      "      - -0.005871772766113281\n",
      "      - 0.2584547996520996\n",
      "      - 0.18304157257080078\n",
      "      - -1.2158730030059814\n",
      "      - 1.5640978813171387\n",
      "      - -0.14909887313842773\n",
      "      - 0.1357436180114746\n",
      "      - -1.3085556030273438\n",
      "      - -0.07461881637573242\n",
      "      - 0.2446737289428711\n",
      "      - 0.0816488265991211\n",
      "      - -0.29033899307250977\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 24032\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 24032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 6\n",
      "iterations_since_restore: 4\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.225\n",
      "  ram_util_percent: 14.8\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07777923389441546\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07925286706844333\n",
      "  mean_inference_ms: 1.1747317235527168\n",
      "  mean_raw_obs_processing_ms: 0.17465418570903413\n",
      "time_since_restore: 19.65340757369995\n",
      "time_this_iter_s: 5.687630653381348\n",
      "time_total_s: 19.65340757369995\n",
      "timers:\n",
      "  learn_throughput: 8790.268\n",
      "  learn_time_ms: 3.64\n",
      "  load_throughput: 119114.065\n",
      "  load_time_ms: 0.269\n",
      "  update_time_ms: 2.651\n",
      "timestamp: 1641931131\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 4000\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 5000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-58-57\n",
      "done: false\n",
      "episode_len_mean: 32.67\n",
      "episode_media: {}\n",
      "episode_reward_max: 137.0\n",
      "episode_reward_mean: 32.67\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 15\n",
      "episodes_total: 179\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 4528\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 9.411138534545898\n",
      "        mean_q: 7.446834564208984\n",
      "        mean_td_error: 0.03650594502687454\n",
      "        min_q: 0.6377754807472229\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.010603904724121094\n",
      "      - -0.3622245192527771\n",
      "      - -1.2302374839782715\n",
      "      - 0.054495811462402344\n",
      "      - 0.3911733627319336\n",
      "      - -0.19349908828735352\n",
      "      - 0.1873607635498047\n",
      "      - 0.024274826049804688\n",
      "      - 1.4294769763946533\n",
      "      - 4.790866374969482\n",
      "      - 0.02715778350830078\n",
      "      - -0.8322386741638184\n",
      "      - -0.17174434661865234\n",
      "      - -0.47800588607788086\n",
      "      - -0.2124471664428711\n",
      "      - -0.8016009330749512\n",
      "      - -0.03728771209716797\n",
      "      - 0.232635498046875\n",
      "      - 0.07146358489990234\n",
      "      - 0.29572200775146484\n",
      "      - -0.005509376525878906\n",
      "      - -0.18052387237548828\n",
      "      - 0.1694316864013672\n",
      "      - 0.04206085205078125\n",
      "      - -0.7321500778198242\n",
      "      - 0.039908409118652344\n",
      "      - -0.14357852935791016\n",
      "      - -1.5024051666259766\n",
      "      - -0.017892837524414062\n",
      "      - 0.06774616241455078\n",
      "      - -0.1395120620727539\n",
      "      - 0.3958778381347656\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 32032\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 32032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 8\n",
      "iterations_since_restore: 5\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 22.950000000000003\n",
      "  ram_util_percent: 14.8125\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07771423957269276\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07928602506528602\n",
      "  mean_inference_ms: 1.1718271005886896\n",
      "  mean_raw_obs_processing_ms: 0.17365403503794924\n",
      "time_since_restore: 25.341490983963013\n",
      "time_this_iter_s: 5.6880834102630615\n",
      "time_total_s: 25.341490983963013\n",
      "timers:\n",
      "  learn_throughput: 9095.252\n",
      "  learn_time_ms: 3.518\n",
      "  load_throughput: 124552.457\n",
      "  load_time_ms: 0.257\n",
      "  update_time_ms: 2.549\n",
      "timestamp: 1641931137\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 5000\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 6000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-59-03\n",
      "done: false\n",
      "episode_len_mean: 40.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 150.0\n",
      "episode_reward_mean: 40.82\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 13\n",
      "episodes_total: 192\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 5536\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 11.340778350830078\n",
      "        mean_q: 9.11974811553955\n",
      "        mean_td_error: 0.6075307130813599\n",
      "        min_q: 0.3063364624977112\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.052620887756347656\n",
      "      - 0.1474447250366211\n",
      "      - -0.48354148864746094\n",
      "      - -0.4393796920776367\n",
      "      - 7.0564165115356445\n",
      "      - -0.34932613372802734\n",
      "      - -0.6936635375022888\n",
      "      - 7.0564165115356445\n",
      "      - -0.09675884246826172\n",
      "      - 0.3754568099975586\n",
      "      - -0.11873340606689453\n",
      "      - 0.6680545806884766\n",
      "      - 0.03704261779785156\n",
      "      - 0.2039012908935547\n",
      "      - 0.20334529876708984\n",
      "      - 1.8918466567993164\n",
      "      - 0.03462409973144531\n",
      "      - -0.4355735778808594\n",
      "      - 0.17548370361328125\n",
      "      - 0.1197195053100586\n",
      "      - 3.029191493988037\n",
      "      - 0.3816967010498047\n",
      "      - -0.0937422513961792\n",
      "      - 0.321197509765625\n",
      "      - 0.24734783172607422\n",
      "      - -0.14447975158691406\n",
      "      - -0.13870906829833984\n",
      "      - 0.2112560272216797\n",
      "      - -0.16086196899414062\n",
      "      - 0.3205547332763672\n",
      "      - 0.10709953308105469\n",
      "      - 0.06027793884277344\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 40032\n",
      "  num_steps_sampled: 6000\n",
      "  num_steps_trained: 40032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 10\n",
      "iterations_since_restore: 6\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.0875\n",
      "  ram_util_percent: 14.8875\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07767685839576302\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07934568798819024\n",
      "  mean_inference_ms: 1.169395908205255\n",
      "  mean_raw_obs_processing_ms: 0.17260930018973533\n",
      "time_since_restore: 31.367645740509033\n",
      "time_this_iter_s: 6.0261547565460205\n",
      "time_total_s: 31.367645740509033\n",
      "timers:\n",
      "  learn_throughput: 8685.152\n",
      "  learn_time_ms: 3.684\n",
      "  load_throughput: 122595.659\n",
      "  load_time_ms: 0.261\n",
      "  update_time_ms: 2.636\n",
      "timestamp: 1641931143\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 6000\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 7000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-59-09\n",
      "done: false\n",
      "episode_len_mean: 48.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 167.0\n",
      "episode_reward_mean: 48.92\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 10\n",
      "episodes_total: 202\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 6544\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 14.5231351852417\n",
      "        mean_q: 11.120903015136719\n",
      "        mean_td_error: -0.1007443517446518\n",
      "        min_q: -0.022861003875732422\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.8322210311889648\n",
      "      - 0.511042594909668\n",
      "      - 0.6259231567382812\n",
      "      - 0.06149864196777344\n",
      "      - 0.1014404296875\n",
      "      - -0.7538728713989258\n",
      "      - -1.1307344436645508\n",
      "      - 0.05668830871582031\n",
      "      - -0.1483907699584961\n",
      "      - -0.3962516784667969\n",
      "      - 0.9315304756164551\n",
      "      - -0.2667865753173828\n",
      "      - 0.43254852294921875\n",
      "      - -0.38956546783447266\n",
      "      - -0.763310432434082\n",
      "      - -1.0228610038757324\n",
      "      - 0.5499820709228516\n",
      "      - 0.3137493133544922\n",
      "      - -0.08421611785888672\n",
      "      - 0.09045219421386719\n",
      "      - 0.39658260345458984\n",
      "      - 0.7430300712585449\n",
      "      - -0.6879348754882812\n",
      "      - -0.5476865768432617\n",
      "      - -0.3571805953979492\n",
      "      - -1.7615089416503906\n",
      "      - -0.127044677734375\n",
      "      - -0.26493263244628906\n",
      "      - 0.1085195541381836\n",
      "      - -0.11568450927734375\n",
      "      - -0.4164094924926758\n",
      "      - 0.2553434371948242\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 48032\n",
      "  num_steps_sampled: 7000\n",
      "  num_steps_trained: 48032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 12\n",
      "iterations_since_restore: 7\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.85\n",
      "  ram_util_percent: 14.9\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07764970844588788\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07937625207375991\n",
      "  mean_inference_ms: 1.1678334051893424\n",
      "  mean_raw_obs_processing_ms: 0.17173536614767052\n",
      "time_since_restore: 37.11836242675781\n",
      "time_this_iter_s: 5.750716686248779\n",
      "time_total_s: 37.11836242675781\n",
      "timers:\n",
      "  learn_throughput: 9514.332\n",
      "  learn_time_ms: 3.363\n",
      "  load_throughput: 128721.327\n",
      "  load_time_ms: 0.249\n",
      "  update_time_ms: 2.455\n",
      "timestamp: 1641931149\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 7000\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 8000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-59-15\n",
      "done: false\n",
      "episode_len_mean: 57.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 57.27\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 7\n",
      "episodes_total: 209\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 7552\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 15.395959854125977\n",
      "        mean_q: 12.645805358886719\n",
      "        mean_td_error: 0.9742021560668945\n",
      "        min_q: 0.6217525005340576\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.7623186111450195\n",
      "      - 0.44716644287109375\n",
      "      - -0.046652793884277344\n",
      "      - 1.3809404373168945\n",
      "      - -0.4510984420776367\n",
      "      - 5.538997650146484\n",
      "      - 0.3379325866699219\n",
      "      - -0.047326087951660156\n",
      "      - -0.08164787292480469\n",
      "      - -1.0544548034667969\n",
      "      - -0.06081104278564453\n",
      "      - 0.3725309371948242\n",
      "      - 10.405420303344727\n",
      "      - -0.22460156679153442\n",
      "      - -0.45078277587890625\n",
      "      - 0.14220237731933594\n",
      "      - 11.657828330993652\n",
      "      - -0.4482903480529785\n",
      "      - 0.5081825256347656\n",
      "      - -0.9691324234008789\n",
      "      - -0.8862667083740234\n",
      "      - 0.7754688262939453\n",
      "      - 0.1085214614868164\n",
      "      - 0.9225530624389648\n",
      "      - 0.05618000030517578\n",
      "      - 0.4736785888671875\n",
      "      - 0.8975229263305664\n",
      "      - 0.06686687469482422\n",
      "      - 0.4419231414794922\n",
      "      - -0.2184772491455078\n",
      "      - 0.19406890869140625\n",
      "      - 0.6237077713012695\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 56032\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 56032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 14\n",
      "iterations_since_restore: 8\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.25\n",
      "  ram_util_percent: 14.912500000000001\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07764267767501566\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07939248707447052\n",
      "  mean_inference_ms: 1.1671017493189375\n",
      "  mean_raw_obs_processing_ms: 0.1711335203458117\n",
      "time_since_restore: 42.791940689086914\n",
      "time_this_iter_s: 5.673578262329102\n",
      "time_total_s: 42.791940689086914\n",
      "timers:\n",
      "  learn_throughput: 8616.349\n",
      "  learn_time_ms: 3.714\n",
      "  load_throughput: 130778.26\n",
      "  load_time_ms: 0.245\n",
      "  update_time_ms: 2.561\n",
      "timestamp: 1641931155\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 8000\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 9000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-59-20\n",
      "done: false\n",
      "episode_len_mean: 66.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 66.12\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 7\n",
      "episodes_total: 216\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 8560\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 18.246471405029297\n",
      "        mean_q: 12.826059341430664\n",
      "        mean_td_error: -0.209104523062706\n",
      "        min_q: -1.1964569091796875\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.4828033447265625\n",
      "      - 0.27493858337402344\n",
      "      - -0.4586048126220703\n",
      "      - 1.6203765869140625\n",
      "      - -0.5620698928833008\n",
      "      - -0.1281280517578125\n",
      "      - 0.4418964385986328\n",
      "      - -0.6010646820068359\n",
      "      - -2.1964569091796875\n",
      "      - -0.9463610649108887\n",
      "      - 0.594120979309082\n",
      "      - -0.21522140502929688\n",
      "      - 0.41666412353515625\n",
      "      - -0.33758544921875\n",
      "      - -0.045322418212890625\n",
      "      - 0.18645572662353516\n",
      "      - 0.005863189697265625\n",
      "      - 0.32310807704925537\n",
      "      - -0.19081878662109375\n",
      "      - 0.5574378967285156\n",
      "      - -0.12540340423583984\n",
      "      - -1.3040590286254883\n",
      "      - -1.5234007835388184\n",
      "      - -0.47388744354248047\n",
      "      - -0.9110870361328125\n",
      "      - -0.587855339050293\n",
      "      - -1.615468978881836\n",
      "      - 0.20021629333496094\n",
      "      - 0.3903169631958008\n",
      "      - 0.15434837341308594\n",
      "      - 0.4382972717285156\n",
      "      - 0.4102134704589844\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 64032\n",
      "  num_steps_sampled: 9000\n",
      "  num_steps_trained: 64032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 16\n",
      "iterations_since_restore: 9\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.512500000000003\n",
      "  ram_util_percent: 14.95\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07763177903452652\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07940477727770866\n",
      "  mean_inference_ms: 1.1663223194074401\n",
      "  mean_raw_obs_processing_ms: 0.17045282658716235\n",
      "time_since_restore: 48.45015215873718\n",
      "time_this_iter_s: 5.6582114696502686\n",
      "time_total_s: 48.45015215873718\n",
      "timers:\n",
      "  learn_throughput: 8779.573\n",
      "  learn_time_ms: 3.645\n",
      "  load_throughput: 117343.703\n",
      "  load_time_ms: 0.273\n",
      "  update_time_ms: 2.619\n",
      "timestamp: 1641931160\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 9000\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 10000\n",
      "custom_metrics: {}\n",
      "date: 2022-01-11_19-59-26\n",
      "done: false\n",
      "episode_len_mean: 74.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 74.44\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 7\n",
      "episodes_total: 223\n",
      "experiment_id: b244bf13b9b945709ab62fc7ab5c0c02\n",
      "hostname: run-61ddddeb0bbd833830273b3e-4dg5f\n",
      "info:\n",
      "  last_target_update_ts: 9568\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 19.70901107788086\n",
      "        mean_q: 15.719871520996094\n",
      "        mean_td_error: 0.677640438079834\n",
      "        min_q: -2.378023147583008\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.23376083374023438\n",
      "      - 0.9604816436767578\n",
      "      - 9.622905731201172\n",
      "      - 0.039714813232421875\n",
      "      - 0.2304401397705078\n",
      "      - 0.014545440673828125\n",
      "      - 0.14394760131835938\n",
      "      - 0.30573463439941406\n",
      "      - -3.378023147583008\n",
      "      - 0.13643264770507812\n",
      "      - 0.06982231140136719\n",
      "      - -3.1821727752685547\n",
      "      - -0.4752006530761719\n",
      "      - 0.04253196716308594\n",
      "      - 0.3107147216796875\n",
      "      - 0.0790252685546875\n",
      "      - 0.18435096740722656\n",
      "      - 0.15758514404296875\n",
      "      - 0.1540241241455078\n",
      "      - 7.030059814453125\n",
      "      - -0.8285560607910156\n",
      "      - 0.5175857543945312\n",
      "      - 0.7425441741943359\n",
      "      - 7.705844879150391\n",
      "      - 0.34461402893066406\n",
      "      - -0.10987472534179688\n",
      "      - 0.5160484313964844\n",
      "      - -1.1129474639892578\n",
      "      - -0.021722793579101562\n",
      "      - 0.8419971466064453\n",
      "      - 0.29768943786621094\n",
      "      - 0.11058998107910156\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 72032\n",
      "  num_steps_sampled: 10000\n",
      "  num_steps_trained: 72032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 18\n",
      "iterations_since_restore: 10\n",
      "node_ip: 10.0.47.167\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 23.6\n",
      "  ram_util_percent: 15.0\n",
      "pid: 632\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07761723032285608\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07941155693923746\n",
      "  mean_inference_ms: 1.1654636160647556\n",
      "  mean_raw_obs_processing_ms: 0.1697189519894475\n",
      "time_since_restore: 54.132829666137695\n",
      "time_this_iter_s: 5.682677507400513\n",
      "time_total_s: 54.132829666137695\n",
      "timers:\n",
      "  learn_throughput: 9160.807\n",
      "  learn_time_ms: 3.493\n",
      "  load_throughput: 129616.348\n",
      "  load_time_ms: 0.247\n",
      "  update_time_ms: 2.517\n",
      "timestamp: 1641931166\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 10000\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.dqn as dqn\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "config = dqn.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 1\n",
    "trainer = dqn.DQNTrainer(config=config, env=\"CartPole-v0\")\n",
    "\n",
    "# Can optionally call trainer.restore(path) to load a checkpoint.\n",
    "\n",
    "for i in range(10):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = trainer.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 100 == 0:\n",
    "       checkpoint = trainer.save()\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the Results\n",
    "\n",
    "Let's take a look at the results of our training.  Which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN_CartPole-v0_2022-01-11_19-58-24rg2tyl6a\r\n"
     ]
    }
   ],
   "source": [
    "#print path to logs\n",
    "\n",
    "!ls ~/ray_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the log file>DQN_CartPole-v0_2022-01-11_19-58-24rg2tyl6a\n"
     ]
    }
   ],
   "source": [
    "logs_path = input('Choose the log file>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>info/last_target_update_ts</th>\n",
       "      <th>info/num_target_updates</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>info/learner/default_policy/td_error</th>\n",
       "      <th>info/learner/default_policy/learner_stats/cur_lr</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/min_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/max_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_td_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.888889</td>\n",
       "      <td>21.888889</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>16.025</td>\n",
       "      <td>14.7000</td>\n",
       "      <td>[-1.0691776  -0.2270276  -0.61742437 -1.017636...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>-0.608496</td>\n",
       "      <td>0.974688</td>\n",
       "      <td>-0.628804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.091837</td>\n",
       "      <td>20.091837</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1504</td>\n",
       "      <td>2</td>\n",
       "      <td>22.550</td>\n",
       "      <td>14.7625</td>\n",
       "      <td>[ 0.06405282  0.07242775 -0.0992837   0.354320...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2.511995</td>\n",
       "      <td>1.954679</td>\n",
       "      <td>3.663027</td>\n",
       "      <td>0.117307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.210000</td>\n",
       "      <td>21.210000</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2512</td>\n",
       "      <td>4</td>\n",
       "      <td>23.300</td>\n",
       "      <td>14.8000</td>\n",
       "      <td>[-0.05341959 -1.2080201   2.5260353  -0.188503...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3.812287</td>\n",
       "      <td>1.533469</td>\n",
       "      <td>5.235931</td>\n",
       "      <td>0.274294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3520</td>\n",
       "      <td>6</td>\n",
       "      <td>23.225</td>\n",
       "      <td>14.8000</td>\n",
       "      <td>[-1.5071988   0.16314983  0.2651515  -0.323109...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.897418</td>\n",
       "      <td>1.211725</td>\n",
       "      <td>7.757925</td>\n",
       "      <td>-0.105739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>32.670000</td>\n",
       "      <td>32.670000</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>4528</td>\n",
       "      <td>8</td>\n",
       "      <td>22.950</td>\n",
       "      <td>14.8125</td>\n",
       "      <td>[-0.0106039  -0.36222452 -1.2302375   0.054495...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>7.446835</td>\n",
       "      <td>0.637776</td>\n",
       "      <td>9.411139</td>\n",
       "      <td>0.036506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                53.0                 9.0            21.888889   \n",
       "1                53.0                 9.0            20.091837   \n",
       "2                78.0                 9.0            21.210000   \n",
       "3                80.0                 9.0            26.070000   \n",
       "4               137.0                 9.0            32.670000   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0         21.888889                  45                    1             1000   \n",
       "1         20.091837                  53                    1             2000   \n",
       "2         21.210000                  40                    1             3000   \n",
       "3         26.070000                  26                    1             4000   \n",
       "4         32.670000                  15                    1             5000   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       "0                    0                   1000  False  ...   \n",
       "1                    0                   2000  False  ...   \n",
       "2                    0                   3000  False  ...   \n",
       "3                    0                   4000  False  ...   \n",
       "4                    0                   5000  False  ...   \n",
       "\n",
       "   info/last_target_update_ts  info/num_target_updates perf/cpu_util_percent  \\\n",
       "0                        1000                        1                16.025   \n",
       "1                        1504                        2                22.550   \n",
       "2                        2512                        4                23.300   \n",
       "3                        3520                        6                23.225   \n",
       "4                        4528                        8                22.950   \n",
       "\n",
       "  perf/ram_util_percent               info/learner/default_policy/td_error  \\\n",
       "0               14.7000  [-1.0691776  -0.2270276  -0.61742437 -1.017636...   \n",
       "1               14.7625  [ 0.06405282  0.07242775 -0.0992837   0.354320...   \n",
       "2               14.8000  [-0.05341959 -1.2080201   2.5260353  -0.188503...   \n",
       "3               14.8000  [-1.5071988   0.16314983  0.2651515  -0.323109...   \n",
       "4               14.8125  [-0.0106039  -0.36222452 -1.2302375   0.054495...   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/cur_lr  \\\n",
       "0                                            0.0005   \n",
       "1                                            0.0005   \n",
       "2                                            0.0005   \n",
       "3                                            0.0005   \n",
       "4                                            0.0005   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/mean_q  \\\n",
       "0                                          0.021092   \n",
       "1                                          2.511995   \n",
       "2                                          3.812287   \n",
       "3                                          5.897418   \n",
       "4                                          7.446835   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/min_q  \\\n",
       "0                                        -0.608496   \n",
       "1                                         1.954679   \n",
       "2                                         1.533469   \n",
       "3                                         1.211725   \n",
       "4                                         0.637776   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/max_q  \\\n",
       "0                                         0.974688   \n",
       "1                                         3.663027   \n",
       "2                                         5.235931   \n",
       "3                                         7.757925   \n",
       "4                                         9.411139   \n",
       "\n",
       "  info/learner/default_policy/learner_stats/mean_td_error  \n",
       "0                                          -0.628804       \n",
       "1                                           0.117307       \n",
       "2                                           0.274294       \n",
       "3                                          -0.105739       \n",
       "4                                           0.036506       \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# choose the path to your output logs\n",
    "logs_path = logs_path\n",
    "data_path = '~/ray_results/{}/progress.csv'.format(logs_path)\n",
    "graph_file = 'progress.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create dataframe with pertinent information and graph the episode reward mean against the episode  per iteration\n",
    "\n",
    "episodes_this_iter = df['episodes_this_iter']\n",
    "episodes_total = df['episodes_total']\n",
    "episodes_reward_mean = df['episode_reward_mean']\n",
    "episodes_reward_max = df['episode_reward_max']\n",
    "episodes_reward_min = df['episode_reward_min']\n",
    "\n",
    "df_episodes = pd.DataFrame(episodes_total)\n",
    "df_episodes['episodes_reward_mean'] = df['episode_reward_mean']\n",
    "df_episodes[\"episodes_reward_min\"] = df['episode_reward_min']\n",
    "df_episodes[\"episodes_reward_max\"] = df['episode_reward_max']\n",
    "\n",
    "df_episodes.plot.line()\n",
    "\n",
    "## here we see the total number of episodes has increased overall but in each iteration, fewer episodes are required \n",
    "## to achieve a higher reward.  We see the algorithm learning more quickly towards the end when it reaches its maximum\n",
    "## iterations and thus its best rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_preprocessor_api': False,\n",
      " '_time_major': False,\n",
      " '_use_default_native_models': False,\n",
      " 'attention_dim': 64,\n",
      " 'attention_head_dim': 32,\n",
      " 'attention_init_gru_gate_bias': 2.0,\n",
      " 'attention_memory_inference': 50,\n",
      " 'attention_memory_training': 50,\n",
      " 'attention_num_heads': 1,\n",
      " 'attention_num_transformer_units': 1,\n",
      " 'attention_position_wise_mlp_dim': 32,\n",
      " 'attention_use_n_prev_actions': 0,\n",
      " 'attention_use_n_prev_rewards': 0,\n",
      " 'conv_activation': 'relu',\n",
      " 'conv_filters': None,\n",
      " 'custom_action_dist': None,\n",
      " 'custom_model': None,\n",
      " 'custom_model_config': {},\n",
      " 'custom_preprocessor': None,\n",
      " 'dim': 84,\n",
      " 'fcnet_activation': 'tanh',\n",
      " 'fcnet_hiddens': [256, 256],\n",
      " 'framestack': True,\n",
      " 'free_log_std': False,\n",
      " 'grayscale': False,\n",
      " 'lstm_cell_size': 256,\n",
      " 'lstm_use_prev_action': False,\n",
      " 'lstm_use_prev_action_reward': -1,\n",
      " 'lstm_use_prev_reward': False,\n",
      " 'max_seq_len': 20,\n",
      " 'no_final_linear': True,\n",
      " 'post_fcnet_activation': 'relu',\n",
      " 'post_fcnet_hiddens': [],\n",
      " 'use_attention': False,\n",
      " 'use_lstm': False,\n",
      " 'vf_share_layers': True,\n",
      " 'zero_mean': True}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "policy = trainer.get_policy()\n",
    "model = policy.model\n",
    "pp.pprint(model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note about Warnings\n",
    "\n",
    "Version 1.6 is validated on the latest edition of Domino, but you see here we chose to use the latest stable version of Ray, 1.9.  This version will occasionally throw some warning about depreciation for future versions of Ray or Pytorch because it is the newest stable version of Ray.  Don't worry too much about the warnings, they will not change the procedures followed to run the code.\n",
    "\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "*Using Pytorch and Ray for a simple finance example using DQN*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
